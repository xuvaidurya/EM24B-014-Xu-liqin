{
  "hash": "fb4252d006bb7a6ed758750ad852fa7d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Xuliqin Practice1127-3\"\noutput: \n  html_document:\n    toc: FALSE\n---\n\n::: {#e8b158a6 .cell execution_count=1}\n``` {.python .cell-code}\n%pip install requests beautifulsoup4\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRequirement already satisfied: requests in d:\\program files\\python3.12.7\\lib\\site-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in d:\\program files\\python3.12.7\\lib\\site-packages (4.12.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python3.12.7\\lib\\site-packages (from requests) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in d:\\program files\\python3.12.7\\lib\\site-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python3.12.7\\lib\\site-packages (from requests) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python3.12.7\\lib\\site-packages (from requests) (2024.8.30)\nRequirement already satisfied: soupsieve>1.2 in d:\\program files\\python3.12.7\\lib\\site-packages (from beautifulsoup4) (2.6)\nNote: you may need to restart the kernel to use updated packages.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n[notice] A new release of pip is available: 24.2 -> 24.3.1\n[notice] To update, run: pythonw.exe -m pip install --upgrade pip\n```\n:::\n:::\n\n\n::: {#18e9650e .cell execution_count=2}\n``` {.python .cell-code}\nimport requests\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n \n# 发送 GET 请求\nresponse = requests.get(url, headers=headers)\nresponse.encoding = 'utf-8'  # 设置编码方式\nhtml_content = response.text  # 获取网页的 HTML 内容\nprint(\"网页内容加载成功！\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n网页内容加载成功！\n```\n:::\n:::\n\n\n::: {#e4fb17f7 .cell execution_count=3}\n``` {.python .cell-code}\nfrom bs4 import BeautifulSoup\n \n# 使用 Beautiful Soup 解析 HTML\nsoup = BeautifulSoup(html_content, 'html.parser')\n \n# 提取电影名称、描述、评分和评价人数\nmovies = []\nfor item in soup.find_all('div', class_='item'):\n    title = item.find('span', class_='title').get_text()  # 电影名称\n    description = item.find('span', class_='inq')  # 电影描述\n    rating = item.find('span', class_='rating_num').get_text()  # 评分\n    votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n    \n    # 如果没有描述，将其置为空字符串\n    if description:\n        description = description.get_text()\n    else:\n        description = ''\n    \n    movie = {\n        \"title\": title,\n        \"description\": description,\n        \"rating\": rating,\n        \"votes\": votes.replace('人评价', '').strip()\n    }\n    movies.append(movie)\n \nprint(\"数据提取成功！\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据提取成功！\n```\n:::\n:::\n\n\n::: {#72197621 .cell execution_count=4}\n``` {.python .cell-code}\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('./file/douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据已成功保存到 douban_top250.csv\n```\n:::\n:::\n\n\n::: {#768e8ed2 .cell execution_count=5}\n``` {.python .cell-code}\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n \n# 发送 GET 请求\nresponse = requests.get(url, headers=headers)\nresponse.encoding = 'utf-8'  # 设置编码方式\nhtml_content = response.text  # 获取网页的 HTML 内容\n \n# 使用 Beautiful Soup 解析 HTML\nsoup = BeautifulSoup(html_content, 'html.parser')\n \n# 提取电影名称、描述、评分和评价人数\nmovies = []\nfor item in soup.find_all('div', class_='item'):\n    title = item.find('span', class_='title').get_text()  # 电影名称\n    description = item.find('span', class_='inq')  # 电影描述\n    rating = item.find('span', class_='rating_num').get_text()  # 评分\n    votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n    \n    # 如果没有描述，将其置为空字符串\n    if description:\n        description = description.get_text()\n    else:\n        description = ''\n    \n    movie = {\n        \"title\": title,\n        \"description\": description,\n        \"rating\": rating,\n        \"votes\": votes.replace('人评价', '').strip()\n    }\n    movies.append(movie)\n \n# 将数据保存到 CSV 文件\nwith open('./file/douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据已成功保存到 douban_top250.csv\n```\n:::\n:::\n\n\n",
    "supporting": [
      "practice1127-3_files"
    ],
    "filters": [],
    "includes": {}
  }
}